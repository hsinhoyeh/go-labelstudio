/*
 * Label Studio API
 *
 * No description provided (generated by Swagger Codegen https://github.com/swagger-api/swagger-codegen)
 *
 * API version: v1.11.0
 * Generated by: Swagger Codegen (https://github.com/swagger-api/swagger-codegen.git)
 */

package swagger

import (
	"time"
)

type Project struct {
	Id int32 `json:"id,omitempty"`
	// Project name. Must be between 3 and 50 characters long.
	Title string `json:"title,omitempty"`
	// Project description
	Description string `json:"description,omitempty"`
	// Label config in XML format. See more about it in documentation
	LabelConfig string `json:"label_config,omitempty"`
	// Labeling instructions in HTML format
	ExpertInstruction string `json:"expert_instruction,omitempty"`
	// Show instructions to the annotator before they start
	ShowInstruction bool `json:"show_instruction,omitempty"`
	// Show a skip button in interface and allow annotators to skip the task
	ShowSkipButton bool `json:"show_skip_button,omitempty"`
	// Allow annotators to submit empty annotations
	EnableEmptyAnnotation bool `json:"enable_empty_annotation,omitempty"`
	// Show annotation history to annotator
	ShowAnnotationHistory bool   `json:"show_annotation_history,omitempty"`
	Organization          int32  `json:"organization,omitempty"`
	Color                 string `json:"color,omitempty"`
	// Maximum number of annotations for one task. If the number of annotations per task is equal or greater to this value, the task is completed (is_labeled=True)
	MaximumAnnotations int32 `json:"maximum_annotations,omitempty"`
	// Whether or not the project is published to annotators
	IsPublished bool `json:"is_published,omitempty"`
	// Machine learning model version
	ModelVersion string `json:"model_version,omitempty"`
	// Whether or not the project is in the middle of being created
	IsDraft   bool        `json:"is_draft,omitempty"`
	CreatedBy *UserSimple `json:"created_by,omitempty"`
	CreatedAt time.Time   `json:"created_at,omitempty"`
	// Minimum number of completed tasks after which model training is started
	MinAnnotationsToStartTraining int32 `json:"min_annotations_to_start_training,omitempty"`
	// Start model training after any annotations are submitted or updated
	StartTrainingOnAnnotationUpdate string `json:"start_training_on_annotation_update,omitempty"`
	// If set, the annotator can view model predictions
	ShowCollabPredictions bool `json:"show_collab_predictions,omitempty"`
	// Tasks with annotations count
	NumTasksWithAnnotations int32 `json:"num_tasks_with_annotations,omitempty"`
	// Total task number in project
	TaskNumber int32 `json:"task_number,omitempty"`
	// Useful annotation number in project not including skipped_annotations_number and ground_truth_number. Total annotations = annotation_number + skipped_annotations_number + ground_truth_number
	UsefulAnnotationNumber int32 `json:"useful_annotation_number,omitempty"`
	// Honeypot annotation number in project
	GroundTruthNumber int32 `json:"ground_truth_number,omitempty"`
	// Skipped by collaborators annotation number in project
	SkippedAnnotationsNumber int32 `json:"skipped_annotations_number,omitempty"`
	// Total annotations number in project including skipped_annotations_number and ground_truth_number.
	TotalAnnotationsNumber int32 `json:"total_annotations_number,omitempty"`
	// Total predictions number in project including skipped_annotations_number, ground_truth_number, and useful_annotation_number.
	TotalPredictionsNumber  int32  `json:"total_predictions_number,omitempty"`
	Sampling                string `json:"sampling,omitempty"`
	ShowGroundTruthFirst    bool   `json:"show_ground_truth_first,omitempty"`
	ShowOverlapFirst        bool   `json:"show_overlap_first,omitempty"`
	OverlapCohortPercentage int32  `json:"overlap_cohort_percentage,omitempty"`
	// Task data credentials: login
	TaskDataLogin string `json:"task_data_login,omitempty"`
	// Task data credentials: password
	TaskDataPassword string `json:"task_data_password,omitempty"`
	// Dict of weights for each control tag in metric calculation. Each control tag (e.g. label or choice) will have it's own key in control weight dict with weight for each label and overall weight.For example, if bounding box annotation with control tag named my_bbox should be included with 0.33 weight in agreement calculation, and the first label Car should be twice more important than Airplaine, then you have to need the specify: {'my_bbox': {'type': 'RectangleLabels', 'labels': {'Car': 1.0, 'Airplaine': 0.5}, 'overall': 0.33}
	ControlWeights interface{} `json:"control_weights,omitempty"`
	// JSON-formatted labeling configuration
	ParsedLabelConfig string `json:"parsed_label_config,omitempty"`
	// Retrieve and display predictions when loading a task
	EvaluatePredictionsAutomatically bool `json:"evaluate_predictions_automatically,omitempty"`
	// Flag to detect is project ready for labeling
	ConfigHasControlTags string `json:"config_has_control_tags,omitempty"`
	SkipQueue            string `json:"skip_queue,omitempty"`
	// Reveal pre-annotations interactively
	RevealPreannotationsInteractively bool `json:"reveal_preannotations_interactively,omitempty"`
	// Pinned date and time
	PinnedAt time.Time `json:"pinned_at,omitempty"`
	// Finished tasks
	FinishedTaskNumber int32  `json:"finished_task_number,omitempty"`
	QueueTotal         string `json:"queue_total,omitempty"`
	QueueDone          string `json:"queue_done,omitempty"`
}
